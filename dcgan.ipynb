{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "latent_dim = 128\n",
    "img_size = 32 * 32 * 3  # CIFAR-10 images are 32x32 RGB\n",
    "batch_size = 128\n",
    "learning_rate = 0.0002\n",
    "num_epochs = 100\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(\"Using device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, transform=transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(input_dim, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator Model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(input_dim, 128, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "generator = Generator(latent_dim, 3).to(device)\n",
    "discriminator = Discriminator(3).to(device)\n",
    "\n",
    "# Loss and Optimizers\n",
    "criterion = nn.BCELoss()\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "\n",
    "# Training Loop (Jupyter Notebook Format)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        # Move images to device\n",
    "        real_imgs = imgs.to(device)\n",
    "        batch_size = real_imgs.size(0)\n",
    "\n",
    "        # Labels for real and fake images\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # Train Discriminator\n",
    "        z = torch.randn(batch_size, latent_dim, 1, 1).to(device)\n",
    "        fake_imgs = generator(z)\n",
    "\n",
    "        real_loss = criterion(discriminator(real_imgs), real_labels)\n",
    "        fake_loss = criterion(discriminator(fake_imgs.detach()), fake_labels)\n",
    "        d_loss = real_loss + fake_loss\n",
    "\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # Train Generator\n",
    "        z = torch.randn(batch_size, latent_dim, 1, 1).to(device)\n",
    "        fake_imgs = generator(z)\n",
    "        g_loss = criterion(discriminator(fake_imgs), real_labels)\n",
    "\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        # Save losses for plotting\n",
    "        g_losses.append(g_loss.item())\n",
    "        d_losses.append(d_loss.item())\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]  D Loss: {d_loss.item():.4f}  G Loss: {g_loss.item():.4f}\")\n",
    "\n",
    "    # Visualize the generated images at certain epochs\n",
    "    if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(16, latent_dim, 1, 1).to(device)\n",
    "            sample_imgs = generator(z).cpu()\n",
    "            grid = torchvision.utils.make_grid(sample_imgs, nrow=4, normalize=True)\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            plt.imshow(np.transpose(grid.numpy(), (1, 2, 0)))\n",
    "            plt.title(f\"Generated Images at Epoch {epoch+1}\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(g_losses, label=\"Generator Loss\")\n",
    "plt.plot(d_losses, label=\"Discriminator Loss\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent Space Interpolation\n",
    "z_start = torch.randn(1, latent_dim, 1, 1).to(device)\n",
    "z_end = torch.randn(1, latent_dim, 1, 1).to(device)\n",
    "\n",
    "# Generate interpolation steps\n",
    "num_interpolations = 10\n",
    "interpolated_images = []\n",
    "\n",
    "for alpha in np.linspace(0, 1, num_interpolations):\n",
    "    z = (1 - alpha) * z_start + alpha * z_end\n",
    "    with torch.no_grad():\n",
    "        interpolated_image = generator(z).cpu()\n",
    "        interpolated_images.append(interpolated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot interpolated images\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i, img in enumerate(interpolated_images):\n",
    "    plt.subplot(1, num_interpolations, i + 1)\n",
    "    plt.imshow(np.transpose(img.squeeze().numpy(), (1, 2, 0)))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Step {i+1}\")\n",
    "plt.suptitle(\"Latent Space Interpolation Between Two Images\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imgs789_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
